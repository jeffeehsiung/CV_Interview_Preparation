{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intersection over union (IoU) is a common evaluation metric for object detection tasks.\n",
    "#  1. NMS\n",
    "#  2. mAP\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def computeIOU(boxA, boxB):\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
    "\n",
    "    # compute the area of both the prediction and ground-truth rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
    "    boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
    "\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "\n",
    "    # return the intersection over union value\n",
    "    return iou\n",
    "\n",
    "# main function\n",
    "def main():\n",
    "    # define the two bounding boxes\n",
    "    boxA = (10, 10, 50, 50)\n",
    "    boxB = (40, 40, 80, 80)\n",
    "\n",
    "    # compute the intersection over union and display it\n",
    "    iou = computeIOU(boxA, boxB)\n",
    "    print(\"IoU: {:.2f}\".format(iou))\n",
    "\n",
    "    # plot the bounding boxes\n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.add_patch(patches.Rectangle((boxA[0], boxA[1]), boxA[2] - boxA[0], boxA[3] - boxA[1], edgecolor='r', facecolor='none'))\n",
    "    ax.add_patch(patches.Rectangle((boxB[0], boxB[1]), boxB[2] - boxB[0], boxB[3] - boxB[1], edgecolor='b', facecolor='none'))\n",
    "    plt.xlim([0, 100])\n",
    "    plt.ylim([0, 100])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Maximum Suppression\n",
    "\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "\n",
    "def nms(boxes: np.ndarray, scores: np.ndarray, iou_threshold: float = 0.5) -> List[int]:\n",
    "    \"\"\"non maximum suppression \"\"\"\n",
    "\n",
    "    # empty boxes candidates checking\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    # step 1: sort the boxes per socre\n",
    "    order = np.argsort(scores)[::-1]\n",
    "    keep = []\n",
    "\n",
    "    # iterate through the order, calcualte the current box IoU with the other boxes, keep the boxes where iou < iou_threshold (different instance). update the order\n",
    "    while order.size > 0:\n",
    "        index = order[0]\n",
    "        keep.append(index)\n",
    "        # check if there is only one box remaining\n",
    "        if order.size == 1:\n",
    "            break\n",
    "\n",
    "        ious = batch_iou(boxes[index], boxes[order[1:]])\n",
    "        indices = np.where(ious <= iou_threshold)[0]\n",
    "        # update order\n",
    "        order = order[indices + 1]\n",
    "    return keep\n",
    "\n",
    "def batch_iou(box1: np.ndarray, boxes: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    batch iou calcualtion. assuming boxes with coordinates x1, x2, y1, y2\n",
    "    \"\"\"\n",
    "    # enforce x2 > x1 and y2 > y1\n",
    "    box1 = np.array([\n",
    "        min(box1[0], box1[2]),\n",
    "        min(box1[1], box1[3]),\n",
    "        max(box1[0], box1[2]),\n",
    "        max(box1[1], box1[3]),\n",
    "    ])\n",
    "    boxes = np.array([\n",
    "        np.min(boxes[:,0], boxes[:,2]),\n",
    "        np.min(boxes[:,1], boxes[:,3]),\n",
    "        np.max(boxes[:,0], boxes[:,2]),\n",
    "        np.max(boxes[:,1], boxes[:,3]),\n",
    "    ]).T\n",
    "    # compute intersection\n",
    "    x1 = np.maximum(box1[0], boxes[:,0])\n",
    "    y1 = np.maximum(box1[1], boxes[:,1])\n",
    "    x2 = np.minimum(box1[2], boxes[:,2])\n",
    "    y2 = np.minimum(box1[3], boxes[:,3])\n",
    "\n",
    "    # intersection : A & B\n",
    "    intersection = np.maximum(0, x2-x1) * np.maximum(0, y2-y1)\n",
    "    # union: A | B - A & B\n",
    "    area1 = (box1[2]-box1[0])*(box1[3]-box1[1])\n",
    "    area2 = (boxes[:,2]-boxes[:,0])*(boxes[:,3]-boxes[:,1])\n",
    "    union = area1 + area2 - intersection\n",
    "    # iou = intersection / union\n",
    "    return intersection/union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hungarian matching for Cost Optimization Problem\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def hungarian_matching(cost_matrix: np.ndarray, threshold: float) -> Tuple[int, int, int]:\n",
    "    \"\"\"Hungarian matching returns TP, FP, FN\"\"\"\n",
    "    # 1. è¡Œå½’çº¦ï¼šæ¯è¡Œå‡å»æœ€å°å€¼\n",
    "    # 2. åˆ—å½’çº¦ï¼šæ¯åˆ—å‡å»æœ€å°å€¼  \n",
    "    # 3. ç”¨æœ€å°‘çš„çº¿è¦†ç›–æ‰€æœ‰çš„0\n",
    "    # 4. å¦‚æœçº¿æ•° < çŸ©é˜µç»´åº¦ï¼Œè°ƒæ•´çŸ©é˜µå¹¶é‡å¤\n",
    "    # 5. æ‰¾åˆ°ç‹¬ç«‹çš„0å…ƒç´ ä½œä¸ºåˆ†é…ç»“æœ\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "\n",
    "    # initialization of tp, fp, fn\n",
    "    tp = fp = fn = 0\n",
    "    matched_gt = set()\n",
    "    matched_pred = set()\n",
    "\n",
    "    for i,j in zip(row_ind, col_ind):\n",
    "        if cost_matrix[i,j] <= threshold:\n",
    "            tp += 1\n",
    "            matched_gt.add(i)\n",
    "            matched_pred.add(j)\n",
    "    fp = len([j for j in range(cost_matrix.shape[1]) if j not in matched_pred])\n",
    "    fn = len([i for i in range(cost_matrix.shape[0]) if i not in matched_gt])\n",
    "\n",
    "    return tp, fp, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import numpy as np\n",
    "def icp(source_points: np.ndarray, target_points: np.ndarray, max_iterations: int = 50, tolerance: float = 1e-6) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    transformation = np.eye(4)\n",
    "    prev_error = 0\n",
    "    for i in range(max_iterations):\n",
    "        # 1. find correspondance per neareast neighbor\n",
    "        correspondances = find_nearest_neighbors(source_points,target_points)\n",
    "        # 2. optimial rigid transform\n",
    "        R, t = compute_rigid_transform(source_points, target_points[correspondances])\n",
    "        # 3. Apply trnasformation\n",
    "        source_points = (R @ source_points.T).T + t\n",
    "        # 4. update transfomration matrix\n",
    "        current_transformation = np.eye(4)\n",
    "        current_transformation[:3, :3] = R\n",
    "        current_transformation[:3, 3] = t\n",
    "        transformation = current_transformation @ transformation\n",
    "        # 5. check convergence\n",
    "        mean_error = np.mean(np.linalg.norm(source_points - target_points[correspondances], axis=1))\n",
    "        if abs(prev_error - mean_error) < tolerance:\n",
    "            break\n",
    "        prev_error = mean_error\n",
    "    return transformation, source_points, mean_error\n",
    "\n",
    "def find_nearest_neighbors(source_points: np.ndarray, target_points: np.ndarray) -> np.ndarray:\n",
    "    from scipy.spatial import cKDTree\n",
    "    tree = cKDTree(target_points)\n",
    "    distances, indices = tree.query(source_points, k=1)\n",
    "    return indices\n",
    "\n",
    "def compute_rigid_transform(A: np.ndarray, B: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    centroid_A = np.mean(A, axis=0)\n",
    "    centroid_B = np.mean(B, axis=0)\n",
    "    # offset to origin\n",
    "    A_centered = A - centroid_A\n",
    "    B_centered = B - centroid_B\n",
    "    # calcualte convariance matrix\n",
    "    H = A_centered.T @ B_centered\n",
    "    # SVD decomposition\n",
    "    U, S, Vt = np.linalg.svd(H)\n",
    "    # compute rotation matrix\n",
    "    R = Vt.T @ U.T\n",
    "    if np.linalg.det(R) < 0:\n",
    "        Vt[-1, :] *= -1\n",
    "        R = Vt.T @ U.T\n",
    "    # compute translation\n",
    "    t = centroid_B - R @ centroid_A\n",
    "    return R, t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_3d_iou(box1: Dict, box2: Dict) -> float:\n",
    "    \"\"\"    \n",
    "    box:{\n",
    "        'center': [x,y,z],\n",
    "        'dimensions': [length, width, height], # l,w,h\n",
    "        'rotation': [rx, ry, rz] # euler\n",
    "    }\n",
    "    \"\"\"\n",
    "    # 1. convert two 3d boxed to world coordinates\n",
    "    corners1 = get_3d_box_corners(box1) \n",
    "    corners2 = get_3d_box_corners(box2) \n",
    "\n",
    "    # 2. compute intersection of 3d boxes\n",
    "    intersection_volume = compute_3d_intersection(corners1, corners2)\n",
    "    # 3. compute respective volume\n",
    "    volume1 = box1['dimensions'][0] * box1['dimensions'][1] * box1['dimensions'][2]\n",
    "    volume2 = box2['dimensions'][0] * box2['dimensions'][1] * box2['dimensions'][2]\n",
    "    # 4. compute IoU\n",
    "    union_volume = volume1 + volume2 - intersection_volume\n",
    "    return intersection_volume / union_volume\n",
    "\n",
    "def get_3d_box_corners(box: Dict, order: str = 'xyz') -> np.ndarray:\n",
    "    \"\"\" obtain the eight corners of 3d boxes\"\"\"\n",
    "    center = np.array(box['center'])\n",
    "    l,w,h = box['dimensions']\n",
    "    corners_local = np.array([\n",
    "        [l/2, w/2, h/2], [l/2, w/2, -h/2],[l/2, -w/2, h/2], [l/2, -w/2, -h/2],\n",
    "        [-l/2, w/2, h/2], [-l/2, w/2, -h/2],[-l/2, -w/2, h/2], [-l/2, -w/2, -h/2]\n",
    "    ])\n",
    "    rotation_matrix = euler_to_rotation_matrix(box['rotation'], str=order)\n",
    "    corners_global = (rotation_matrix @ corners_local.T).T + center\n",
    "    return corners_global\n",
    "\n",
    "def euler_to_rotation_matrix(euler_angles: np.ndarray, order: str = 'zyx')\n",
    "    \"\"\"\n",
    "    euler_angles: [roll, pitch, yaw] or [Î±, Î², Î³]\n",
    "    order: e.g. 'zyx', 'xyz', etc\n",
    "    \"\"\"    \n",
    "    roll, pitch, yaw = euler_angles\n",
    "    Rx = np.array([\n",
    "        [1,0,0],\n",
    "        [0, np.cos(roll), -np.sin(roll)],\n",
    "        [0, np.sin(roll), np.cos(roll)]\n",
    "    ])\n",
    "    Ry = np.array([\n",
    "        [np.cos(pitch), 0, np.sin(pitch)],\n",
    "        [0,1,0],\n",
    "        [-np.sin(pitch), 0, np.cos(pitch)]\n",
    "    ])\n",
    "    Rz = np.array([\n",
    "        [np.cos(yaw), -np.sin(yaw), 0],\n",
    "        [np.sin(yaw), np.cos(yaw), 0],\n",
    "        [0,0,1]\n",
    "    ])\n",
    "\n",
    "    if order ==  'xyz': # å¸¸è§äºæœºå™¨äººå­¦ (åèˆª-ä¿¯ä»°-æ»šè½¬)\n",
    "        R = Rz @ Ry @ Rx    # æ³¨æ„: çŸ©é˜µä¹˜æ³•ä»å³åˆ°å·¦åº”ç”¨\n",
    "    elif order ==  'zyx':\n",
    "        R = Rx @ Ry @ Rz\n",
    "    else:\n",
    "        raise ValueError(f'Unsupported rotation order: {order}')\n",
    "    return R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def farthest_point_sampling(points:np.ndarray, k:int) -> np.ndarray:\n",
    "    # point to node partition with a fixed parition size\n",
    "    n, dim  = points.shape\n",
    "    # initialization\n",
    "    centroids = np.zeros(k, dtype=int)\n",
    "    distance = np.ones(n) * 1e10        # set inifinite to avoid false assignment\n",
    "    farthest = np.random.randint(0,n)   # random farthest index initialization\n",
    "\n",
    "    for i in range(k):\n",
    "        centroids[i] = farthest\n",
    "        centroid = points[farthest]\n",
    "        # euclidians distance: points (N,D), centroid(D,), points - centroind (N,D)\n",
    "        # np.sum(...,axis=1) -> sum along the feature dimension\n",
    "        dist = np.sum((points - centroid) ** 2, axis=1)\n",
    "        # update with the minimum distance\n",
    "        mask = dist < distance\n",
    "        distance[mask] = dist[mask]\n",
    "        # chose the farthest point\n",
    "        farthest = np.argmax(distance)\n",
    "\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1) (1, 1)\n",
      "æœ€è¿‘é‚»ç´¢å¼•: [388]\n",
      "è·ç¦»: [0.04164108]\n",
      "æœ€è¿‘é‚»ç´¢å¼•: [388 269 916 141 412]\n",
      "è·ç¦»: [0.04164108 0.12194955 0.13840224 0.18172525 0.20388875]\n"
     ]
    }
   ],
   "source": [
    "# KD-Tree for KNN\n",
    "from sklearn.neighbors import KDTree, NearestNeighbors\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "\n",
    "\"\"\"\n",
    "    KNNç®—æ³•åŸç†ï¼š\n",
    "    1. è®¡ç®—æŸ¥è¯¢ç‚¹ä¸æ‰€æœ‰ç‚¹çš„è·ç¦»\n",
    "    2. é€‰æ‹©è·ç¦»æœ€å°çš„kä¸ªç‚¹\n",
    "    3. è¿”å›è¿™äº›ç‚¹çš„ç´¢å¼•å’Œè·ç¦»\n",
    "\"\"\"\n",
    "\n",
    "def knn(points:np.ndarray, query_point: np.ndarray, k: int = 5) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    # initialize KD tree\n",
    "    tree = KDTree(points, leaf_size=40)\n",
    "    # query k nearest neighbor\n",
    "    distances, indices = tree.query(query_point.reshape(1,-1), k=1)\n",
    "    print(indices.shape, distances.shape)\n",
    "    return indices[0], distances[0]\n",
    "\n",
    "from scipy.spatial import KDTree as scipy_KDTree\n",
    "def knn_scipy(points:np.ndarray, query_point: np.ndarray, k: int = 5) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    tree = scipy_KDTree(points)\n",
    "    distances, indices = tree.query(query_point, k=k)\n",
    "    return indices, distances\n",
    "\n",
    "# ä½¿ç”¨ç¤ºä¾‹\n",
    "points = np.random.randn(1000, 3)  # 1000ä¸ª3Dç‚¹\n",
    "query = np.array([0, 0, 0])\n",
    "indices, distances = knn(points, query, k=5)\n",
    "indices_scipy, distance_scipy = knn_scipy(points, query, k=5)\n",
    "print(f\"æœ€è¿‘é‚»ç´¢å¼•: {indices}\")\n",
    "print(f\"è·ç¦»: {distances}\")\n",
    "print(f\"æœ€è¿‘é‚»ç´¢å¼•: {indices_scipy}\")\n",
    "print(f\"è·ç¦»: {distance_scipy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv2d\n",
    "\n",
    "def conv2d(input_array: np.array, kernel: np.ndarray, stride: int = 1, padding: int = 0) -> np.ndarray:\n",
    "    # check padding to preserve feature map and allow to include edges\n",
    "    if padding > 0:\n",
    "        # pad_width: ((before axis0, after axis0),(before axis1, after axis1))\n",
    "        input_padded = np.pad(input_array,((padding, padding),(padding, padding)), mode='constant')\n",
    "    else:\n",
    "        input_padded = input_array\n",
    "    \n",
    "    H,W = input_padded.shape\n",
    "    kH, kW = kernel.shape\n",
    "\n",
    "    out_h = (H-kH) // stride + 1\n",
    "    out_w = (W-kW) // stride + 1\n",
    "\n",
    "    # initialzie output vector\n",
    "    output = np.zeros((out_h, out_w))\n",
    "\n",
    "    for i in range(out_h):\n",
    "        for j in range(out_w):\n",
    "            h_start = i * stride\n",
    "            w_start = j * stride\n",
    "            region = input_padded[h_start:h_start+kH, w_start:w_start+kW]\n",
    "            output[i,j] = np.sum(region * kernel)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lane similarity camera\n",
    "\n",
    "def lane_similarity_camera(lane1: np.ndarray, lane2: np.ndarray, image:np.ndarray = None) -> float:\n",
    "    \"\"\"lane1, lane2: (image_x,iamge_y)\"\"\"\n",
    "    # geometric similarity\n",
    "    geometric_sim = calculate_geometric_similarity(lane1, lane2) \n",
    "    # image appearance similatiry\n",
    "    if image is not None:\n",
    "        appearance_sim = calcualte_appearance_similarity(lane1, lane2, image)\n",
    "        return 0.7 * geometric_sim + 0.3 * appearance_sim\n",
    "    else:\n",
    "        return geometric_sim\n",
    "\n",
    "def calculate_geometric_similarity(lane1: np.ndarray, lane2: np.ndarray)-> float:\n",
    "    # method 1: dynamic time windowing similairty for varied number of points\n",
    "    if len(lane1) != len(lane2):\n",
    "        return dtw_similairty(lane1, lane2)\n",
    "    # method 2: inter point distance similarity\n",
    "    point_distances = np.linalg.norm(lane1 - lane2, axis=1)\n",
    "    avg_distance = np.mean(point_distances)\n",
    "    # method 3: curvature similarity\n",
    "    curvature_sim = curvature_similarity(lane1, lane2)\n",
    "    direction_sim = direction_similarity(lane1, lane2)\n",
    "    \n",
    "    distance_sim = np.exp(-avg_distance / 10.0)\n",
    "    geometric_sim = 0.5 * distance_sim + 0.3 * curvature_sim + 0.2 * direction_sim\n",
    "    return geometric_sim\n",
    "\n",
    "def dtw_similairty(lane1: np.ndarray, lane2: np.ndarray)-> float:\n",
    "    from dtaidistance import dtw\n",
    "    distance = dtw.distance(lane1, lane2)\n",
    "    similarity = np.exp(-distance/max(len(lane1),len(lane2)))\n",
    "    return similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lane similarity lidar\n",
    "\n",
    "def lane_similarity_lidar(lane1_points: np.ndarray, lane2_points: np.ndarray, ground_plane:np.ndarray = None) -> float:\n",
    "    \"\"\"lane1_points, lane1_points: (N,3)\"\"\"\n",
    "    # 1. spatial distance similarity\n",
    "    spatial_sim = calcualte_spatial_similarity(lane1_points,lane2_points)\n",
    "    # 2. structural similarity\n",
    "    structural_sim = calculate_structural_similarity(lane1_points,lane2_points)\n",
    "    # 3. ground projection similarity (if gorund plane polynomial is known)\n",
    "    if ground_plane is not None:\n",
    "        ground_sim = calculate_ground_projection_similarity(\n",
    "            lane1_points, lane2_points, ground_plane\n",
    "        )\n",
    "        return 0.4 * spatial_sim + 0.4 * structural_sim + 0.2 * ground_sim\n",
    "    else:\n",
    "        return 0.6 * spatial_sim + 0.4 * structural_sim\n",
    "\n",
    "def calcualte_spatial_similarity(points1: np.ndarray, points2: np.ndarray) -> float:\n",
    "    # chamfer distance\n",
    "    def chamfer_distance(p1,p2):\n",
    "        from scipy.spatial import cKDTree\n",
    "        tree1 = cKDTree(p1)\n",
    "        tree2 = cKDTree(p2)\n",
    "        dist1 = tree1.query(p2)[0]\n",
    "        dist2 = tree2.query(p1)[0]\n",
    "        return (np.mean(dist1)+np.mean(dist2))/2\n",
    "    chamfer_dist = chamfer_distance(points1, points2)\n",
    "    return np.exp(-chamfer_dist/0.5)\n",
    "\n",
    "def calculate_structural_similarity(points1: np.ndarray, points2: np.ndarray) -> float:\n",
    "    # 1. curvature similarity\n",
    "    curvature1 = compute_curvature(points1)\n",
    "    curvature2 = compute_curvature(points2)\n",
    "    curvature_sim = 1.0 - abs(curvature1 - curvature2) / max(curvature1, curvature2)\n",
    "    # direction similarity\n",
    "    direction1 = compute_principal_direction(points1)\n",
    "    direction2 = compute_principal_direction(points2)\n",
    "\n",
    "    density_sim = calcualte_density_similarity(points1, points2)\n",
    "    return 0.4 * curvature_sim + 0.4 * direction_sim + 0.2 * density_sim\n",
    "\n",
    "from scipy import interpolate\n",
    "def compute_curvature(points: np.ndarray) -> float:\n",
    "    if (len(points) < 3):\n",
    "        return 0.0\n",
    "    # method 1: three points curvature\n",
    "    curvatures = []\n",
    "    for i in ranges(1, len(points)-1):\n",
    "        p1, p2, p3 = points[i-1], points[i], points[i+1]\n",
    "        curvature = curvature_from_three_points(p1, p2, p3)\n",
    "        curvatures.append(curvature)\n",
    "    return np.mean(curvatures) if curvatures else 0.0\n",
    "\n",
    "def curvature_from_three_points(p1: np.ndarray, p2: np.ndarray, p3: np.ndarray) -> float:\n",
    "    \"\"\"é€šè¿‡ä¸‰ç‚¹è®¡ç®—æ›²ç‡ (ä½¿ç”¨ä¸‰è§’å½¢å¤–æ¥åœ†æ–¹æ³•)\"\"\"\n",
    "    # compute triangle edges\n",
    "    a = np.linalg.norm(p2-p3)\n",
    "    b = np.linalg.norm(p1-p3)\n",
    "    c = np.linalg.norm(p1-p2)\n",
    "\n",
    "    # compute triagnle area\n",
    "    s = (a+b+c)/2\n",
    "    area = np.sqrt(s*(s-a)*(s-b)*(s-c))\n",
    "    if area < 1e-10 or a*b*c < 1e-10:\n",
    "        return 0.0\n",
    "    # æ›²ç‡ = 4 * é¢ç§¯ / (è¾¹é•¿ä¹˜ç§¯)\n",
    "    curvature = 4 * area / (a*b*c)\n",
    "\n",
    "def curvature_similarity_simplified(lane1: np.ndarray, lane2: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    è®¡ç®—ä¸¤æ¡è½¦é“çº¿çš„æ›²ç‡ç›¸ä¼¼åº¦ - ä½¿ç”¨æ»‘åŠ¨çª—å£\n",
    "    è¿”å›: 0-1ä¹‹é—´çš„ç›¸ä¼¼åº¦åˆ†æ•°ï¼Œ1è¡¨ç¤ºå®Œå…¨ç›¸åŒ\n",
    "    \"\"\"\n",
    "    curvature1 = compute_curvature(lane1)\n",
    "    curvature2 = compute_curvature(lane2)\n",
    "\n",
    "    if curvature1 == 0 and curvature2 == 0:\n",
    "        return 1.0  # both straight\n",
    "    # calculate relative difference\n",
    "    max_curvature = max(abs(curvature1), abs(curvature2))\n",
    "    curvature_diff = abs(curvature1 - curvature2)\n",
    "    # similarity = 1 - normalized differences\n",
    "    similarity = 1.0 - (curvature_diff/(max_curvature + 1e-8))\n",
    "    return max(0.0, min(1.0, similarity))\n",
    "\n",
    "def curvature_similarity(lane1: np.ndarray, lane2: np.ndarray, window_size: int = 5) -> float:\n",
    "    \"\"\"\n",
    "    è®¡ç®—ä¸¤æ¡è½¦é“çº¿çš„æ›²ç‡ç›¸ä¼¼åº¦ - ä½¿ç”¨æ»‘åŠ¨çª—å£\n",
    "    è¿”å›: 0-1ä¹‹é—´çš„ç›¸ä¼¼åº¦åˆ†æ•°ï¼Œ1è¡¨ç¤ºå®Œå…¨ç›¸åŒ\n",
    "    \"\"\"\n",
    "    if len(lane1) < window_size or len(lane2) < window_size:\n",
    "        return curvature_similarity_simplified(lane1, lane2)\n",
    "    \n",
    "    curvatures1 = compute_curvature_sequence(lane1, window_size)\n",
    "    curvatures2 = compute_curvature_sequence(lane2, window_size)\n",
    "\n",
    "    # algin the length of curvature\n",
    "    min_len = min(len(curvature1), len(curvature2))\n",
    "    curvatures1 = curvatures1[:min_len]\n",
    "    curvatures2 = curvatures2[:min_len]\n",
    "    if min_len == 0:\n",
    "        return 0.0\n",
    "    correlation = np.corrcoef(curvatures1, curvatures2)[0,1]\n",
    "    if np.isnan(correlation):\n",
    "        return 0.0\n",
    "    return (correlation + 1) / 2\n",
    "\n",
    "def compute_curvature_sequence(points: np.ndarray, window_size: int = 5) -> np.ndarray:\n",
    "    curvatures = []\n",
    "    for i in range(len(points) - window_size + 1):\n",
    "        window_points = points[i:i + window_size]\n",
    "        curvature = compute_curvature(windows_points)\n",
    "        curvatures.append(curvature)\n",
    "    return np.array(curvatures)\n",
    "\n",
    "def compute_direction(points: np.ndarray) -> float:\n",
    "    if len(points) < 2:\n",
    "        return 0.0\n",
    "    start_point = points[0]\n",
    "    end_point = points[-1]\n",
    "    direction_vector = end_point - start_point\n",
    "    # phi between y and x\n",
    "    angle = np.arctan2(direction_vector[1], direction_vector[0])\n",
    "    return angle\n",
    "\n",
    "def compute_direction_sequence(points: np.ndarray, segment_length: int = 5) -> float:\n",
    "    if(len(points) < segment_length):\n",
    "        return np.array([compute_direction(points)])\n",
    "    directions = []\n",
    "    for i in range(0, len(points) - segment_length + 1, segment_length // 2):\n",
    "        segment = points[i:i + segment_length]\n",
    "        direction = compute_direction(segment)\n",
    "        directions.append(direction)\n",
    "    return np.array(directions)\n",
    "\n",
    "def compute_principal_direction(points: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"PCA\"\"\"\n",
    "    if len(points) < 2:\n",
    "        return np.array([1.0. 0.0])\n",
    "    # ä¸­å¿ƒåŒ–ç‚¹äº‘\n",
    "    centered = points - np.mean(points, axis=0)\n",
    "    # è®¡ç®—åæ–¹å·®çŸ©é˜µ\n",
    "    cov_matrix = np.cov(centered.T)\n",
    "    # è®¡ç®—ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)\n",
    "    # é€‰æ‹©æœ€å¤§ç‰¹å¾å€¼å¯¹åº”çš„ç‰¹å¾å‘é‡ (ä¸»æ–¹å‘)\n",
    "    principal_idx = np.argmax(eigenvalues)\n",
    "    principal_direction = eigenvectors[:, principal_idx]\n",
    "    # ç¡®ä¿æ–¹å‘ä¸€è‡´æ€§ (æŒ‡å‘è½¦é“çº¿å»¶ä¼¸æ–¹å‘)\n",
    "    if principal_direction[0] < 0: # ç¡®ä¿xåˆ†é‡ä¸ºæ­£\n",
    "        principal_direction = -principal_direction\n",
    "    return principal_direction\n",
    "\n",
    "def direction_similarity(lane1: np.ndarray, lane2: np.ndarray) -> float:\n",
    "    dir1 = compute_principal_direction(lane1)\n",
    "    dir2 = compute_principal_direction(lane2)\n",
    "    # compute angle cosine\n",
    "    cosine_similarity = np.dot(dir1, dir2)\n",
    "    return max(0.0, cosine_similarity)\n",
    "\n",
    "def direction_similarity_detailed(lane1: np.ndarray, lane2: np.ndarray, segment_length: int = 5) -> float:\n",
    "    dirs1 = compute_direction_sequence(lane1, segment_length)\n",
    "    dirs2 = compute_direction_sequence(lane2, segment_length)\n",
    "\n",
    "    min_len = min(len(dirs1), len(dirs2))\n",
    "    if min_len == 0:\n",
    "        return 0.0\n",
    "    dirs1 = dirs1[:min_len]\n",
    "    dirs2 = dirs2[:min_len]\n",
    "    # è®¡ç®—æ–¹å‘è§’åº¦å·®å¼‚\n",
    "    angle_diffs = np.abs(dirs1 - dirs2)\n",
    "    # å¤„ç†è§’åº¦å‘¨æœŸæ€§é—®é¢˜ (è§’åº¦å·®åº”è¯¥åœ¨0-piä¹‹é—´)\n",
    "    angle_diffs = np.minimum(angle_diffs, 2*np.pi - angle_diffs)\n",
    "    mean_angle_diff = np.mean(angle_diffs)\n",
    "    # å°†è§’åº¦å·®å¼‚è½¬æ¢ä¸ºç›¸ä¼¼åº¦\n",
    "    # è§’åº¦å·®ä¸º0æ—¶ç›¸ä¼¼åº¦ä¸º1ï¼Œè§’åº¦å·®ä¸ºpi/2æ—¶ç›¸ä¼¼åº¦ä¸º0\n",
    "    similarity = 1.0 - (mean_angle_diff / (np.pi/2))\n",
    "    return max(0.0, min(1.0, similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict\n",
    "import numpy as np\n",
    "\n",
    "def match_lanes_hugarian(\n",
    "        gt_lanes: List[np.ndarray],\n",
    "        pred_lanes: List[np.ndarray],\n",
    "        threshold: float = 0.8\n",
    ") -> Dict[str, float]:\n",
    "    # initialize cost matrix\n",
    "    cost_matrix = np.zeros(len(gt_lanes), len(pred_lanes))\n",
    "    for i, gt_lane in enumerate(gt_lanes):\n",
    "        for j, pred_lane in enumerate(pred_lanes):\n",
    "            cost_matrix[i,j] = 1- lane_similarity(gt_lane, pred_lane)\n",
    "    # hugarian matching\n",
    "    from scipy.optimize import linear_sum_assignment\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "    # tp, fp, fn\n",
    "    tp = fp = fn = 0\n",
    "    for i,j in zip(row_ind, col_ind):\n",
    "        if cost_matrix[i,j] <= (1-threshold):\n",
    "            tp += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "            fp += 1\n",
    "    # precision, recall, f1\n",
    "    precision = tp /(tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lane_polynomial(points: np.ndarray, degree: int = 3) -> np.ndarray:\n",
    "    x = points[:,0]\n",
    "    y = points[:,1]\n",
    "    coefficients = np.polyfit(y, x, degree)\n",
    "    return coefficients\n",
    "\n",
    "def calculate_lane_curvature(coefficients: np.ndarray, y:float) -> float:\n",
    "    # curvature formula: k = |f''(y)| / (1 + f'(y)^2)^(3/2)\n",
    "    poly = np.poly1d(coefficients)\n",
    "    first_deriv = poly.deriv()(y)\n",
    "    second_deriv = poly.deriv(2)(y)\n",
    "    curvature = np.abs(second_deriv) / (1 + first_deriv ** 2) ** 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def ransac_ground_segmentation(points:np.ndarray, num_iteration: int = 100, distance_threshold: float = 0.1) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    best_plane = None\n",
    "    best_inliers = []\n",
    "\n",
    "    for _ in range(num_iteration):\n",
    "        # three points formulates a plane\n",
    "        sample_indices = np.random.choice(len(points), 3, replace=False)\n",
    "        sample_points = points[sample_indices]\n",
    "        # formualte plane Ax + By + Cz + D = 0\n",
    "        v1 = sample_points[1] - sample_points[0]\n",
    "        v2 = sample_points[2] - sample_points[0]\n",
    "        normal = np.cross(v1, v2)\n",
    "        normal = normal / (np.linalg.norm(normal)+ 1e-8)\n",
    "        D = -np.dot(normal, sample_points[0])\n",
    "        # point-to-plane distance\n",
    "        distances = np.abs(points @ normal + D) / np.linalg.norm(normal)\n",
    "        # find inliers\n",
    "        inliers = np.where(distances < distance_threshold)[0]\n",
    "        if len(inliers) > len(best_inliers):\n",
    "            best_inliers = inliers\n",
    "            best_plane = (normal, D)\n",
    "    ground_points = points[best_inliers]\n",
    "    non_ground_points = points[~np.isin(np.arange(len(points)), best_inliers)]\n",
    "    return ground_points, non_ground_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# lidar to camer projection\n",
    "def lidar_to_camera_projection(lidar_points: np.ndarray, camera_matrix: np.ndarray, dist_coeffs: np.ndarray, extrinsic_matrix: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    æ¿€å…‰é›·è¾¾åæ ‡ç³» \n",
    "    â†“ å¤–å‚çŸ©é˜µ\n",
    "    ç›¸æœºåæ ‡ç³»  \n",
    "    â†“ å»é™¤ç•¸å˜\n",
    "    å½’ä¸€åŒ–ç›¸æœºåæ ‡ç³»\n",
    "    â†“ å†…å‚çŸ©é˜µ  \n",
    "    å›¾åƒåæ ‡ç³» (åƒç´ åæ ‡)\n",
    "    å†…å‚çŸ©é˜µï¼šæè¿°ç›¸æœºåæ ‡ç³»åˆ°å›¾åƒåæ ‡ç³»çš„å˜æ¢\n",
    "    å¤–å‚çŸ©é˜µï¼šæè¿°ä¸–ç•Œåæ ‡ç³»åˆ°ç›¸æœºåæ ‡ç³»çš„å˜æ¢\n",
    "            åæ ‡å˜æ¢ï¼šä¸–ç•Œç‚¹ -> ç›¸æœºç‚¹\n",
    "            åæ ‡å˜æ¢å…¬å¼ï¼š\n",
    "            # point_camera = R @ point_world + t\n",
    "            ä½†ä»£ç æ˜¯ï¼špoint_camera = point_lidar @ R.T + t\n",
    "            å¦‚æœ extrinsic_matrix è¡¨ç¤ºä»ç›¸æœºåˆ°æ¿€å…‰é›·è¾¾çš„å˜æ¢ (camera_to_lidar)\n",
    "            é‚£ä¹ˆä»æ¿€å…‰é›·è¾¾åˆ°ç›¸æœºéœ€è¦å–é€†ï¼š\n",
    "            # R_lidar_to_camera = R_camera_to_lidar.T\n",
    "            # t_lidar_to_camera = -R_camera_to_lidar.T @ t_camera_to_lidar\n",
    "    ç•¸å˜ç³»æ•°ï¼šæè¿°çœŸå®ç›¸æœºé•œå¤´ä¸ç†æƒ³é’ˆå­”æ¨¡å‹çš„åå·®\n",
    "    \"\"\"\n",
    "    # 1. coordinate system transformation: lidar coord system to camera coord system\n",
    "    points_camera = lidar_points @ extrinsic_matrix[:3, :3].T + extrinsic_matrix[:3, 3]\n",
    "    # 2. remove points beyond camera screen\n",
    "    mask = points_camera[:, 2] > 0\n",
    "    points_camera = points[mask]\n",
    "    # project to 2d plane\n",
    "    points_2d, _ = cv2.projectPoints(points_camera, np.zeros(3), np.zeros(3), dist_coeffs)\n",
    "    points_2d = points_2d.reshape(-1,2) # ä»(N,1,2)å˜ä¸º(N,2)\n",
    "    # filter points outside of image boarder\n",
    "    height, width = 1080, 1920\n",
    "    valid_mask = (points_2d[:,0] >= 0) & (points_2d[:,0] <= width) & (points_2d[:,1] >= 0) & (points_2d[:,1] <= height)\n",
    "    return points_2d[valid_mask], valid_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self Attention\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_dim: int, num_heads: int = 8):\n",
    "        # instantiate module interface\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads \n",
    "        assert self.head_dim * num_heads == embed_dim\n",
    "        # instantiate linear transform layers (N,N)\n",
    "        self.qkv = nn.Linear(embed_dim, embed_dim * 3)\n",
    "        self.proj = nn.Linear(embed_dim, embed_dim)\n",
    "    \n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "        # decode input dimensions\n",
    "        batch_size, seq_len, embed_dim = x.shape\n",
    "        # encode query, key, and value\n",
    "        qkv = self.qkv(x)                                                           # [batch_size, seq_len, 3 * embed_dim]\n",
    "        # instantiate multihead \n",
    "        qkv = qkv.reshape(batch_size, seq_len, 3, self.num_heads, self.head_dim)    # [batch_size, seq_len, 3, num_heads, head_dim]\n",
    "        qkv = qkv.permute(2, 0, 3, 1, 4)                                            # [3, batch, num_heads, seq_len, head_dim]\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]                                            # æ¯ä¸ªéƒ½æ˜¯ [batch_size, num_heads, seq_len, head_dim]\n",
    "        # compute attention weights\n",
    "        scale = self.head_dim ** -0.5\n",
    "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) * scale                  # [batch_size, num_heads, seq_len, seq_len]\n",
    "        attn_weight = F.softmax(attn_scores, dim=-1)                                # [batch_size, num_heads, seq_len, seq_len]\n",
    "        # apply the attention weights\n",
    "        output = torch.matmul(attn_weight, v)                                       # [batch_size, num_heads, seq_len, head_dim]\n",
    "        output = output.transpose(1,2).contiguous.view(batch_size, seq_len, embed_dim) # [batch_size, seq_len, num_heads * head_dim]\n",
    "        output = self.proj(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List\n",
    "from collections import deque\n",
    "\n",
    "def level_order_traversal(root: Optional['TreeNode']) -> List[List[int]]:\n",
    "    \"\"\"äºŒå‰æ¨¹å±¤æ¬¡éæ­·\"\"\"\n",
    "    if not root:\n",
    "        return []\n",
    "    \n",
    "    result = []\n",
    "    queue = deque([root])\n",
    "    \n",
    "    while queue:\n",
    "        level_size = len(queue)\n",
    "        level_nodes = []\n",
    "        \n",
    "        for _ in range(level_size):\n",
    "            node = queue.popleft()\n",
    "            level_nodes.append(node.val)\n",
    "            if node.left:\n",
    "                queue.append(node.left)\n",
    "            if node.right:\n",
    "                queue.append(node.right)\n",
    "        \n",
    "        result.append(level_nodes)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def reverse_linked_list(head: Optional['ListNode']) -> Optional['ListNode']:\n",
    "    \"\"\"éˆè¡¨åè½‰\"\"\"\n",
    "    prev = None\n",
    "    current = head\n",
    "    \n",
    "    while current:\n",
    "        next_temp = current.next\n",
    "        current.next = prev\n",
    "        prev = current\n",
    "        current = next_temp\n",
    "    \n",
    "    return prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_path_sum(grid: List[List[int]]) -> int:\n",
    "    \"\"\"æœ€å°è·¯å¾‘å’Œ\"\"\"\n",
    "    if not grid or not grid[0]:\n",
    "        return 0\n",
    "    \n",
    "    m, n = len(grid), len(grid[0])\n",
    "    dp = [[0] * n for _ in range(m)]\n",
    "    dp[0][0] = grid[0][0]\n",
    "    \n",
    "    for i in range(1, m):\n",
    "        dp[i][0] = dp[i-1][0] + grid[i][0]\n",
    "    for j in range(1, n):\n",
    "        dp[0][j] = dp[0][j-1] + grid[0][j]\n",
    "    \n",
    "    for i in range(1, m):\n",
    "        for j in range(1, n):\n",
    "            dp[i][j] = min(dp[i-1][j], dp[i][j-1]) + grid[i][j]\n",
    "    \n",
    "    return dp[m-1][n-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PointNetFeatureExtractor(nn.Module):\n",
    "    \"\"\"PointNetç‰¹å¾æå–å™¨ - 3Dæ·±åº¦å­¦ä¹ çš„åŸºçŸ³\"\"\"\n",
    "    def __init__(self, feature_dim: int = 1024):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = nn.Conv1d(128, feature_dim, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(feature_dim)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"x: (B, 3, N)\"\"\"\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]  # Max pooling\n",
    "        x = x.view(-1, 1024)\n",
    "        return x\n",
    "\n",
    "class Transformer3D(nn.Module):\n",
    "    \"\"\"3Dç‚¹äº‘Transformer\"\"\"\n",
    "    def __init__(self, input_dim: int = 3, hidden_dim: int = 256, num_heads: int = 8):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(input_dim, hidden_dim)\n",
    "        self.attention = nn.MultiheadAttention(hidden_dim, num_heads)\n",
    "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
    "        self.norm2 = nn.LayerNorm(hidden_dim)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim * 4, hidden_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, points: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"points: (N, 3)\"\"\"\n",
    "        x = self.input_proj(points)  # (N, hidden_dim)\n",
    "        \n",
    "        # Self-attention\n",
    "        attn_out, _ = self.attention(x, x, x)\n",
    "        x = self.norm1(x + attn_out)\n",
    "        \n",
    "        # Feed-forward\n",
    "        ff_out = self.ffn(x)\n",
    "        x = self.norm2(x + ff_out)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_synchronization(lidar_data: Dict, camera_data: Dict, \n",
    "                           gps_data: Dict, timestamp_tolerance: float = 0.01) -> Dict:\n",
    "    \"\"\"\n",
    "    å¤šä¼ æ„Ÿå™¨æ—¶é—´åŒæ­¥ - å®é™…å·¥ç¨‹ä¸­çš„å…³é”®é—®é¢˜\n",
    "    \"\"\"\n",
    "    # 1. æ‰¾åˆ°æ—¶é—´æˆ³æœ€æ¥è¿‘çš„æ•°æ®å¸§\n",
    "    lidar_ts = lidar_data['timestamp']\n",
    "    camera_ts = camera_data['timestamp']\n",
    "    gps_ts = gps_data['timestamp']\n",
    "    \n",
    "    # 2. æ£€æŸ¥æ—¶é—´åŒæ­¥æ€§\n",
    "    max_diff = max(abs(lidar_ts - camera_ts), abs(lidar_ts - gps_ts))\n",
    "    if max_diff > timestamp_tolerance:\n",
    "        print(f\"è­¦å‘Šï¼šä¼ æ„Ÿå™¨æ—¶é—´ä¸åŒæ­¥ï¼Œæœ€å¤§å·®å¼‚: {max_diff:.3f}s\")\n",
    "    \n",
    "    # 3. åº”ç”¨æ—¶é—´è¡¥å¿ï¼ˆå¦‚æœçŸ¥é“ä¼ æ„Ÿå™¨å»¶è¿Ÿï¼‰\n",
    "    compensated_data = apply_time_compensation(\n",
    "        lidar_data, camera_data, gps_data\n",
    "    )\n",
    "    \n",
    "    return compensated_data\n",
    "\n",
    "def spatial_calibration(lidar_points: np.ndarray, camera_matrix: np.ndarray,\n",
    "                       lidar_to_camera_transform: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    æ¿€å…‰é›·è¾¾åˆ°ç›¸æœºçš„ç©ºé—´æ ‡å®š\n",
    "    \"\"\"\n",
    "    # 1. åæ ‡å˜æ¢: æ¿€å…‰é›·è¾¾åæ ‡ç³» -> ç›¸æœºåæ ‡ç³»\n",
    "    points_camera = (lidar_to_camera_transform[:3, :3] @ lidar_points.T + \n",
    "                    lidar_to_camera_transform[:3, 3].reshape(3, 1)).T\n",
    "    \n",
    "    # 2. æŠ•å½±åˆ°å›¾åƒå¹³é¢\n",
    "    points_2d = (camera_matrix @ points_camera.T).T\n",
    "    points_2d = points_2d[:, :2] / points_2d[:, 2:3]  # é½æ¬¡åæ ‡å½’ä¸€åŒ–\n",
    "    \n",
    "    return points_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LaneSimilarityNet(nn.Module):\n",
    "    \"\"\"æ·±åº¦å­¦ä¹ è½¦é“çº¿ç›¸ä¼¼åº¦ç½‘ç»œ\"\"\"\n",
    "    \n",
    "    def __init__(self, feature_dim: int = 128):\n",
    "        super().__init__()\n",
    "        self.lane_encoder = nn.Sequential(\n",
    "            nn.Linear(6, 64),  # å‡è®¾æ¯ä¸ªç‚¹æœ‰(x,y,z,curvature,direction,confidence)\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(128, feature_dim)\n",
    "        )\n",
    "        \n",
    "        self.similarity_head = nn.Sequential(\n",
    "            nn.Linear(feature_dim * 2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, lane1: torch.Tensor, lane2: torch.Tensor) -> torch.Tensor:\n",
    "        # ç¼–ç è½¦é“çº¿ç‰¹å¾\n",
    "        feat1 = self.lane_encoder(lane1).mean(dim=0)  # å…¨å±€å¹³å‡æ± åŒ–\n",
    "        feat2 = self.lane_encoder(lane2).mean(dim=0)\n",
    "        \n",
    "        # è®¡ç®—ç›¸ä¼¼åº¦\n",
    "        combined = torch.cat([feat1, feat2], dim=-1)\n",
    "        similarity = self.similarity_head(combined)\n",
    "        \n",
    "        return similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ•’ é•·æ™‚é–“å­¸ç¿’è¨ˆåŠƒï¼ˆ12-14å°æ™‚ï¼‰\n",
    "\n",
    "ç¬¬ä¸€éšæ®µï¼šæ ¸å¿ƒçªç ´ (4å°æ™‚)\n",
    "\n",
    "08:00-09:30ï¼šNMS + IoU + åŒˆç‰™åˆ©åŒ¹é… (åè¦†ç·´ç¿’3é)\n",
    "09:30-10:30ï¼šé»é›²åœ°é¢åˆ†å‰² + FPS\n",
    "10:30-12:00ï¼šè»Šé“ç·šæª¢æ¸¬è©•ä¼°æŒ‡æ¨™\n",
    "ç¬¬äºŒéšæ®µï¼šé‡é»å¼·åŒ– (4å°æ™‚)\n",
    "\n",
    "13:00-14:30ï¼šKNN + KD-Tree + Conv2D\n",
    "14:30-16:00ï¼šC++åº•å±¤å…«è‚¡è¤‡ç¿’\n",
    "16:00-17:00ï¼šé …ç›®æŠ€è¡“ç´°ç¯€æº–å‚™\n",
    "17:00-18:00ï¼šåæ¨™è®Šæ› + å¤šå‚³æ„Ÿå™¨èåˆ\n",
    "ç¬¬ä¸‰éšæ®µï¼šåŸºç¤éå›º (3å°æ™‚)\n",
    "\n",
    "19:00-20:00ï¼šäºŒå‰æ¨¹ + éˆè¡¨ + å‹•æ…‹è¦åŠƒ\n",
    "20:00-21:00ï¼šæ‰€æœ‰é¡Œç›®ç¬¬äºŒéç·´ç¿’\n",
    "21:00-22:00ï¼šæ¨¡æ“¬é¢è©¦ + å¼±é …å¼·åŒ–\n",
    "ç¬¬å››éšæ®µï¼šè¡åˆºè¤‡ç¿’ (2å°æ™‚)\n",
    "\n",
    "22:00-23:00ï¼šé‡é»é¡Œç›®ç¬¬ä¸‰éç·´ç¿’\n",
    "23:00-24:00ï¼šé¢ç¶“å•é¡Œè‡ªå•è‡ªç­”\n",
    "ğŸ’¡ å­¸ç¿’å»ºè­°\n",
    "\n",
    "æ¯é¡Œéƒ½è¦æ‰‹å¯«ï¼Œä¸è¦åªçœ‹ä¸å¯«\n",
    "å…ˆç†è§£æ€è·¯ï¼Œå†å¯«ä»£ç¢¼\n",
    "æ³¨é‡é‚Šç•Œæ¢ä»¶å’ŒéŒ¯èª¤è™•ç†\n",
    "ç·´ç¿’å£é ­è§£é‡‹ç®—æ³•æ€è·¯\n",
    "å®šæœŸä¼‘æ¯ï¼Œä¿æŒç²¾åŠ›"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
